{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SLI_baseline.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZiYJjAbVNVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81tLQmMBOvzc",
        "colab_type": "code",
        "outputId": "7dad19c2-a7bd-4f88-ccdb-acb50057189e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# there are 1045 data in dataset\n",
        "dialogue = \"\"\n",
        "firstLine = None\n",
        "count = -1\n",
        "f = open('All_Data_morphemes.txt', 'r')\n",
        "age = []\n",
        "sex = []\n",
        "X = []\n",
        "y = []\n",
        "for line in f:\n",
        "    if (line == \"<data>\\n\"):\n",
        "        if (count != -1):\n",
        "            X.append(dialogue)\n",
        "        dialogue = \"\"\n",
        "        count += 1\n",
        "        firstLine = None\n",
        "        continue\n",
        "    if (firstLine == None):\n",
        "        firstLine = line\n",
        "        #firstSplit = firstLine.split(', ')\n",
        "        #print(firstSplit)\n",
        "        #age.append(firstSplit[0])\n",
        "        #sex.append(firstSplit[1])\n",
        "        #if (firstSplit[2] == \"SLI\\n\"):\n",
        "        if (firstLine == \"SLI\\n\"):\n",        
        "            y.append(1)\n",
        "        else:\n",
        "            y.append(0)\n",
        "        continue\n",
        "    dialogue = dialogue + \" \" + line\n",
        "X.append(dialogue)\n",
        "print(\"Data Size:\", len(X), len(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Size: 1045 1045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFTRRlbWOpDt",
        "colab_type": "code",
        "outputId": "03c614c1-a612-4348-d562-9366f7f3c8c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_LlBNHqVSSN",
        "colab_type": "code",
        "outputId": "823c2fee-94bf-4ee3-9f9e-255d9e234756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhwwwifWVPdF",
        "colab_type": "code",
        "outputId": "86f17a55-842f-417c-d3a6-f01ea7d839de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TEbpZVrVjJl",
        "colab_type": "code",
        "outputId": "1da92304-b807-4b1f-ff49-d5b0ddb4d0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Set the output directory for saving model file\n",
        "# Optionally, set a GCP bucket location\n",
        "\n",
        "OUTPUT_DIR = 'output'#@param {type:\"string\"}\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = True #@param {type:\"boolean\"}\n",
        "#@markdown Set USE_BUCKET and BUCKET if you want to (optionally) store model output on GCP bucket.\n",
        "USE_BUCKET = True #@param {type:\"boolean\"}\n",
        "BUCKET = 'nlp_sli_bucket' #@param {type:\"string\"}\n",
        "\n",
        "if USE_BUCKET:\n",
        "  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    # Doesn't matter if the directory didn't exist\n",
        "    pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://nlp_sli_bucket/output *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXlL2cZMaYmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=29)\n",
        "tr = {'dialogue':X_train, 'sli':y_train}\n",
        "te = {'dialogue':X_test, 'sli':y_test}\n",
        "train = pd.DataFrame(tr)\n",
        "test = pd.DataFrame(te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn3BlSRCat-O",
        "colab_type": "code",
        "outputId": "fbda1f4d-d601-4f35-c468-905e90e1ee54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(X_train), len(y_train))\n",
        "print(len(X_test), len(y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "836 836\n",
            "209 209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPbn0FZ-WShH",
        "colab_type": "code",
        "outputId": "4f867b49-b0d7-457d-81ee-f267980d6778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['dialogue', 'sli'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCNuPudZWT5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'dialogue'\n",
        "LABEL_COLUMN = 'sli'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5dLnu1KWVu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNML1X0kWXp2",
        "colab_type": "code",
        "outputId": "64ad80c3-b614-4083-d4d6-db9af630572a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      #print(vocab_file)\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=\"/content/vocab.txt\", do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MteSJO78WZjX",
        "colab_type": "code",
        "outputId": "fefdc07e-2cce-4364-d82d-cbb01002e9c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "#tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")\n",
        "tokenizer.tokenize(\"Test sample PAUSE1 this is right? PAUSE2 Okay. Pause3\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test',\n",
              " 'sample',\n",
              " 'pause1',\n",
              " 'this',\n",
              " 'is',\n",
              " 'right',\n",
              " '?',\n",
              " 'pause2',\n",
              " 'okay',\n",
              " '.',\n",
              " 'pause3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7MBOzopWbLm",
        "colab_type": "code",
        "outputId": "416fccc6-6260-4382-9230-b981a74e95ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# We'll set sequences to be at most 512 tokens long. (BERT maximum = 512)\n",
        "MAX_SEQ_LENGTH = 512\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 836\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] when lisa and raymond got home from school their mother asked them where they were gonna go out for dinner that night and she asked them where they wanted to go and they both shouted mcdonald ##s and then they got into the car and drove to the nearest mcdonald ##s and when they got in there lisa didn ' t know what to order raymond and mother knew what to order and raymond wanted a big vanilla milk ##sha ##ke a cheese ##burg ##er and a coke and mother wanted a salad finally lisa made up her mind she wanted a coke a chocolate ice + cream and a happy _ meal when mother and raymond ordered their food and then lisa did she told the clerk what she wanted to order and the clerk said it was twelve dollars when mother reached into get her purse it wasn ' t there once there was a little boy named dan he was getting up from school one day and the and he was holding his alarm clock and then when he went to breakfast table but when he tried to pour the milk it spilled and then he tried to clean it up and then after he had breakfast he tied his shoes and he went to the bus stop but when he got to the bus stop the bus was already leaving and then dan had ##ta walk all the way to school and it was two miles and then when he got there the teacher said that you ' re late and then he went into school and did his work once there was a little girl and a little boy the girl ' s name was michael and the boy ' s name was sam they went to the park on tuesday morning and then when they got there they saw an alien family coming out with a dog and sam didn ' t wanna go near any closer but michael she wanted to go meet the alien family and pet their dog and then sam tried to run home except michael first grabbed his arm and ran to the alien family to meet them but then when they got there the aliens were gone they were going back inside their ship and then michael decided to go inside the ship and meet them except the problem was the the rooms and everything looked weird and they couldn ' t find the aliens but then they finally found them and then they met them and then they decided to go get their parents for them to meet them and then when they went to get their parents they woke up because it was just a dream [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] when lisa and raymond got home from school their mother asked them where they were gonna go out for dinner that night and she asked them where they wanted to go and they both shouted mcdonald ##s and then they got into the car and drove to the nearest mcdonald ##s and when they got in there lisa didn ' t know what to order raymond and mother knew what to order and raymond wanted a big vanilla milk ##sha ##ke a cheese ##burg ##er and a coke and mother wanted a salad finally lisa made up her mind she wanted a coke a chocolate ice + cream and a happy _ meal when mother and raymond ordered their food and then lisa did she told the clerk what she wanted to order and the clerk said it was twelve dollars when mother reached into get her purse it wasn ' t there once there was a little boy named dan he was getting up from school one day and the and he was holding his alarm clock and then when he went to breakfast table but when he tried to pour the milk it spilled and then he tried to clean it up and then after he had breakfast he tied his shoes and he went to the bus stop but when he got to the bus stop the bus was already leaving and then dan had ##ta walk all the way to school and it was two miles and then when he got there the teacher said that you ' re late and then he went into school and did his work once there was a little girl and a little boy the girl ' s name was michael and the boy ' s name was sam they went to the park on tuesday morning and then when they got there they saw an alien family coming out with a dog and sam didn ' t wanna go near any closer but michael she wanted to go meet the alien family and pet their dog and then sam tried to run home except michael first grabbed his arm and ran to the alien family to meet them but then when they got there the aliens were gone they were going back inside their ship and then michael decided to go inside the ship and meet them except the problem was the the rooms and everything looked weird and they couldn ' t find the aliens but then they finally found them and then they met them and then they decided to go get their parents for them to meet them and then when they went to get their parents they woke up because it was just a dream [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2043 7059 1998 7638 2288 2188 2013 2082 2037 2388 2356 2068 2073 2027 2020 6069 2175 2041 2005 4596 2008 2305 1998 2016 2356 2068 2073 2027 2359 2000 2175 1998 2027 2119 6626 9383 2015 1998 2059 2027 2288 2046 1996 2482 1998 5225 2000 1996 7205 9383 2015 1998 2043 2027 2288 1999 2045 7059 2134 1005 1056 2113 2054 2000 2344 7638 1998 2388 2354 2054 2000 2344 1998 7638 2359 1037 2502 21161 6501 7377 3489 1037 8808 4645 2121 1998 1037 14492 1998 2388 2359 1037 16521 2633 7059 2081 2039 2014 2568 2016 2359 1037 14492 1037 7967 3256 1009 6949 1998 1037 3407 1035 7954 2043 2388 1998 7638 3641 2037 2833 1998 2059 7059 2106 2016 2409 1996 7805 2054 2016 2359 2000 2344 1998 1996 7805 2056 2009 2001 4376 6363 2043 2388 2584 2046 2131 2014 8722 2009 2347 1005 1056 2045 2320 2045 2001 1037 2210 2879 2315 4907 2002 2001 2893 2039 2013 2082 2028 2154 1998 1996 1998 2002 2001 3173 2010 8598 5119 1998 2059 2043 2002 2253 2000 6350 2795 2021 2043 2002 2699 2000 10364 1996 6501 2009 13439 1998 2059 2002 2699 2000 4550 2009 2039 1998 2059 2044 2002 2018 6350 2002 5079 2010 6007 1998 2002 2253 2000 1996 3902 2644 2021 2043 2002 2288 2000 1996 3902 2644 1996 3902 2001 2525 2975 1998 2059 4907 2018 2696 3328 2035 1996 2126 2000 2082 1998 2009 2001 2048 2661 1998 2059 2043 2002 2288 2045 1996 3836 2056 2008 2017 1005 2128 2397 1998 2059 2002 2253 2046 2082 1998 2106 2010 2147 2320 2045 2001 1037 2210 2611 1998 1037 2210 2879 1996 2611 1005 1055 2171 2001 2745 1998 1996 2879 1005 1055 2171 2001 3520 2027 2253 2000 1996 2380 2006 9857 2851 1998 2059 2043 2027 2288 2045 2027 2387 2019 7344 2155 2746 2041 2007 1037 3899 1998 3520 2134 1005 1056 10587 2175 2379 2151 3553 2021 2745 2016 2359 2000 2175 3113 1996 7344 2155 1998 9004 2037 3899 1998 2059 3520 2699 2000 2448 2188 3272 2745 2034 4046 2010 2849 1998 2743 2000 1996 7344 2155 2000 3113 2068 2021 2059 2043 2027 2288 2045 1996 12114 2020 2908 2027 2020 2183 2067 2503 2037 2911 1998 2059 2745 2787 2000 2175 2503 1996 2911 1998 3113 2068 3272 1996 3291 2001 1996 1996 4734 1998 2673 2246 6881 1998 2027 2481 1005 1056 2424 1996 12114 2021 2059 2027 2633 2179 2068 1998 2059 2027 2777 2068 1998 2059 2027 2787 2000 2175 2131 2037 3008 2005 2068 2000 3113 2068 1998 2059 2043 2027 2253 2000 2131 2037 3008 2027 8271 2039 2138 2009 2001 2074 1037 3959 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2043 7059 1998 7638 2288 2188 2013 2082 2037 2388 2356 2068 2073 2027 2020 6069 2175 2041 2005 4596 2008 2305 1998 2016 2356 2068 2073 2027 2359 2000 2175 1998 2027 2119 6626 9383 2015 1998 2059 2027 2288 2046 1996 2482 1998 5225 2000 1996 7205 9383 2015 1998 2043 2027 2288 1999 2045 7059 2134 1005 1056 2113 2054 2000 2344 7638 1998 2388 2354 2054 2000 2344 1998 7638 2359 1037 2502 21161 6501 7377 3489 1037 8808 4645 2121 1998 1037 14492 1998 2388 2359 1037 16521 2633 7059 2081 2039 2014 2568 2016 2359 1037 14492 1037 7967 3256 1009 6949 1998 1037 3407 1035 7954 2043 2388 1998 7638 3641 2037 2833 1998 2059 7059 2106 2016 2409 1996 7805 2054 2016 2359 2000 2344 1998 1996 7805 2056 2009 2001 4376 6363 2043 2388 2584 2046 2131 2014 8722 2009 2347 1005 1056 2045 2320 2045 2001 1037 2210 2879 2315 4907 2002 2001 2893 2039 2013 2082 2028 2154 1998 1996 1998 2002 2001 3173 2010 8598 5119 1998 2059 2043 2002 2253 2000 6350 2795 2021 2043 2002 2699 2000 10364 1996 6501 2009 13439 1998 2059 2002 2699 2000 4550 2009 2039 1998 2059 2044 2002 2018 6350 2002 5079 2010 6007 1998 2002 2253 2000 1996 3902 2644 2021 2043 2002 2288 2000 1996 3902 2644 1996 3902 2001 2525 2975 1998 2059 4907 2018 2696 3328 2035 1996 2126 2000 2082 1998 2009 2001 2048 2661 1998 2059 2043 2002 2288 2045 1996 3836 2056 2008 2017 1005 2128 2397 1998 2059 2002 2253 2046 2082 1998 2106 2010 2147 2320 2045 2001 1037 2210 2611 1998 1037 2210 2879 1996 2611 1005 1055 2171 2001 2745 1998 1996 2879 1005 1055 2171 2001 3520 2027 2253 2000 1996 2380 2006 9857 2851 1998 2059 2043 2027 2288 2045 2027 2387 2019 7344 2155 2746 2041 2007 1037 3899 1998 3520 2134 1005 1056 10587 2175 2379 2151 3553 2021 2745 2016 2359 2000 2175 3113 1996 7344 2155 1998 9004 2037 3899 1998 2059 3520 2699 2000 2448 2188 3272 2745 2034 4046 2010 2849 1998 2743 2000 1996 7344 2155 2000 3113 2068 2021 2059 2043 2027 2288 2045 1996 12114 2020 2908 2027 2020 2183 2067 2503 2037 2911 1998 2059 2745 2787 2000 2175 2503 1996 2911 1998 3113 2068 3272 1996 3291 2001 1996 1996 4734 1998 2673 2246 6881 1998 2027 2481 1005 1056 2424 1996 12114 2021 2059 2027 2633 2179 2068 1998 2059 2027 2777 2068 1998 2059 2027 2787 2000 2175 2131 2037 3008 2005 2068 2000 3113 2068 1998 2059 2043 2027 2253 2000 2131 2037 3008 2027 8271 2039 2138 2009 2001 2074 1037 3959 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] pause1 these two pause1 animals were playing ball the ball fell into the water one of the animals went swimming to get the ball the animals got the ball and played with it they jumped and the lady pause1 had the ball now it is done these two animals went swimming these two pause1 animals pause1 went to walk to the diving board both of them were running pause2 down the pause1 aisle one of the pause1 animals pause1 fell pause1 and cut his knee both the life ##guard came and put a bandage on it she was pause1 happy that she got a banda ##id she pause1 hugged the life ##guard she sat on a bench pause1 scared now these two kids pause1 went swimming with a airplane they flew it they hold it pause1 and then fl ##ied it and then pause1 they played with it then it fell in the water and it broke they both was scared pause1 of pause1 the airplane they teased each other the life ##guard said no toys in the water the two kids said sorry then the life ##guard jumped into the water and got it pause1 the life ##guard could not get the airplane the mom got a net and then put it in the water she got the pause1 net and put it on the airplane and got the plane the mom give ##d it back to the animal fixed he hugged it now these two kids were playing in the sand ##box these two kids made a sand ##castle these kids put sand over top of the castle it broke they made a dinosaur kind of and now this one guy was waiting for one of other of a kid they played with food they had a party pause1 with food they drink ##ed juice one of them got full they ate candy they threw all the candy stuff on the ground and never picked it up they played pause1 with the sand ##box the pause1 dad went to get one of them they pulled the tee ##shi ##rt he said pause1 open your mouth they walked home and walked home in the bushes and now these two guys were pause1 pause1 riding a pause1 wagon with a balloon on it they pause1 waved at somebody they un ##tie ##d the balloon it went up in the pause2 air it went in the pause1 sky a clown was selling more balloons a guy said can i have that one pause1 the pause1 clown said it is pause1 five cents pause1 they had both pause1 money and pause1 the clown did not give him the balloon they went to see a doctor after pause1 and said pause1 the clown did not give ##d me a balloon then pause1 they got pause1 two money then after they pause1 hold it and the end [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] pause1 these two pause1 animals were playing ball the ball fell into the water one of the animals went swimming to get the ball the animals got the ball and played with it they jumped and the lady pause1 had the ball now it is done these two animals went swimming these two pause1 animals pause1 went to walk to the diving board both of them were running pause2 down the pause1 aisle one of the pause1 animals pause1 fell pause1 and cut his knee both the life ##guard came and put a bandage on it she was pause1 happy that she got a banda ##id she pause1 hugged the life ##guard she sat on a bench pause1 scared now these two kids pause1 went swimming with a airplane they flew it they hold it pause1 and then fl ##ied it and then pause1 they played with it then it fell in the water and it broke they both was scared pause1 of pause1 the airplane they teased each other the life ##guard said no toys in the water the two kids said sorry then the life ##guard jumped into the water and got it pause1 the life ##guard could not get the airplane the mom got a net and then put it in the water she got the pause1 net and put it on the airplane and got the plane the mom give ##d it back to the animal fixed he hugged it now these two kids were playing in the sand ##box these two kids made a sand ##castle these kids put sand over top of the castle it broke they made a dinosaur kind of and now this one guy was waiting for one of other of a kid they played with food they had a party pause1 with food they drink ##ed juice one of them got full they ate candy they threw all the candy stuff on the ground and never picked it up they played pause1 with the sand ##box the pause1 dad went to get one of them they pulled the tee ##shi ##rt he said pause1 open your mouth they walked home and walked home in the bushes and now these two guys were pause1 pause1 riding a pause1 wagon with a balloon on it they pause1 waved at somebody they un ##tie ##d the balloon it went up in the pause2 air it went in the pause1 sky a clown was selling more balloons a guy said can i have that one pause1 the pause1 clown said it is pause1 five cents pause1 they had both pause1 money and pause1 the clown did not give him the balloon they went to see a doctor after pause1 and said pause1 the clown did not give ##d me a balloon then pause1 they got pause1 two money then after they pause1 hold it and the end [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1 2122 2048 1 4176 2020 2652 3608 1996 3608 3062 2046 1996 2300 2028 1997 1996 4176 2253 5742 2000 2131 1996 3608 1996 4176 2288 1996 3608 1998 2209 2007 2009 2027 5598 1998 1996 3203 1 2018 1996 3608 2085 2009 2003 2589 2122 2048 4176 2253 5742 2122 2048 1 4176 1 2253 2000 3328 2000 1996 9404 2604 2119 1997 2068 2020 2770 2 2091 1996 1 12485 2028 1997 1996 1 4176 1 3062 1 1998 3013 2010 6181 2119 1996 2166 18405 2234 1998 2404 1037 24446 2006 2009 2016 2001 1 3407 2008 2016 2288 1037 24112 3593 2016 1 10308 1996 2166 18405 2016 2938 2006 1037 6847 1 6015 2085 2122 2048 4268 1 2253 5742 2007 1037 13297 2027 5520 2009 2027 2907 2009 1 1998 2059 13109 6340 2009 1998 2059 1 2027 2209 2007 2009 2059 2009 3062 1999 1996 2300 1998 2009 3631 2027 2119 2001 6015 1 1997 1 1996 13297 2027 13074 2169 2060 1996 2166 18405 2056 2053 10899 1999 1996 2300 1996 2048 4268 2056 3374 2059 1996 2166 18405 5598 2046 1996 2300 1998 2288 2009 1 1996 2166 18405 2071 2025 2131 1996 13297 1996 3566 2288 1037 5658 1998 2059 2404 2009 1999 1996 2300 2016 2288 1996 1 5658 1998 2404 2009 2006 1996 13297 1998 2288 1996 4946 1996 3566 2507 2094 2009 2067 2000 1996 4111 4964 2002 10308 2009 2085 2122 2048 4268 2020 2652 1999 1996 5472 8758 2122 2048 4268 2081 1037 5472 23662 2122 4268 2404 5472 2058 2327 1997 1996 3317 2009 3631 2027 2081 1037 15799 2785 1997 1998 2085 2023 2028 3124 2001 3403 2005 2028 1997 2060 1997 1037 4845 2027 2209 2007 2833 2027 2018 1037 2283 1 2007 2833 2027 4392 2098 10869 2028 1997 2068 2288 2440 2027 8823 9485 2027 4711 2035 1996 9485 4933 2006 1996 2598 1998 2196 3856 2009 2039 2027 2209 1 2007 1996 5472 8758 1996 1 3611 2253 2000 2131 2028 1997 2068 2027 2766 1996 17170 6182 5339 2002 2056 1 2330 2115 2677 2027 2939 2188 1998 2939 2188 1999 1996 14568 1998 2085 2122 2048 4364 2020 1 1 5559 1037 1 9540 2007 1037 13212 2006 2009 2027 1 7147 2012 8307 2027 4895 9515 2094 1996 13212 2009 2253 2039 1999 1996 2 2250 2009 2253 1999 1996 1 3712 1037 15912 2001 4855 2062 22163 1037 3124 2056 2064 1045 2031 2008 2028 1 1996 1 15912 2056 2009 2003 1 2274 16653 1 2027 2018 2119 1 2769 1998 1 1996 15912 2106 2025 2507 2032 1996 13212 2027 2253 2000 2156 1037 3460 2044 1 1998 2056 1 1996 15912 2106 2025 2507 2094 2033 1037 13212 2059 1 2027 2288 1 2048 2769 2059 2044 2027 1 2907 2009 1998 1996 2203 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1 2122 2048 1 4176 2020 2652 3608 1996 3608 3062 2046 1996 2300 2028 1997 1996 4176 2253 5742 2000 2131 1996 3608 1996 4176 2288 1996 3608 1998 2209 2007 2009 2027 5598 1998 1996 3203 1 2018 1996 3608 2085 2009 2003 2589 2122 2048 4176 2253 5742 2122 2048 1 4176 1 2253 2000 3328 2000 1996 9404 2604 2119 1997 2068 2020 2770 2 2091 1996 1 12485 2028 1997 1996 1 4176 1 3062 1 1998 3013 2010 6181 2119 1996 2166 18405 2234 1998 2404 1037 24446 2006 2009 2016 2001 1 3407 2008 2016 2288 1037 24112 3593 2016 1 10308 1996 2166 18405 2016 2938 2006 1037 6847 1 6015 2085 2122 2048 4268 1 2253 5742 2007 1037 13297 2027 5520 2009 2027 2907 2009 1 1998 2059 13109 6340 2009 1998 2059 1 2027 2209 2007 2009 2059 2009 3062 1999 1996 2300 1998 2009 3631 2027 2119 2001 6015 1 1997 1 1996 13297 2027 13074 2169 2060 1996 2166 18405 2056 2053 10899 1999 1996 2300 1996 2048 4268 2056 3374 2059 1996 2166 18405 5598 2046 1996 2300 1998 2288 2009 1 1996 2166 18405 2071 2025 2131 1996 13297 1996 3566 2288 1037 5658 1998 2059 2404 2009 1999 1996 2300 2016 2288 1996 1 5658 1998 2404 2009 2006 1996 13297 1998 2288 1996 4946 1996 3566 2507 2094 2009 2067 2000 1996 4111 4964 2002 10308 2009 2085 2122 2048 4268 2020 2652 1999 1996 5472 8758 2122 2048 4268 2081 1037 5472 23662 2122 4268 2404 5472 2058 2327 1997 1996 3317 2009 3631 2027 2081 1037 15799 2785 1997 1998 2085 2023 2028 3124 2001 3403 2005 2028 1997 2060 1997 1037 4845 2027 2209 2007 2833 2027 2018 1037 2283 1 2007 2833 2027 4392 2098 10869 2028 1997 2068 2288 2440 2027 8823 9485 2027 4711 2035 1996 9485 4933 2006 1996 2598 1998 2196 3856 2009 2039 2027 2209 1 2007 1996 5472 8758 1996 1 3611 2253 2000 2131 2028 1997 2068 2027 2766 1996 17170 6182 5339 2002 2056 1 2330 2115 2677 2027 2939 2188 1998 2939 2188 1999 1996 14568 1998 2085 2122 2048 4364 2020 1 1 5559 1037 1 9540 2007 1037 13212 2006 2009 2027 1 7147 2012 8307 2027 4895 9515 2094 1996 13212 2009 2253 2039 1999 1996 2 2250 2009 2253 1999 1996 1 3712 1037 15912 2001 4855 2062 22163 1037 3124 2056 2064 1045 2031 2008 2028 1 1996 1 15912 2056 2009 2003 1 2274 16653 1 2027 2018 2119 1 2769 1998 1 1996 15912 2106 2025 2507 2032 1996 13212 2027 2253 2000 2156 1037 3460 2044 1 1998 2056 1 1996 15912 2106 2025 2507 2094 2033 1037 13212 2059 1 2027 2288 1 2048 2769 2059 2044 2027 1 2907 2009 1998 1996 2203 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] mom said let go out to eat and the kid said mcdonald ##s so they jumped in the car and went to mcdonald ##s the nearest one and the mom and and jacob know what they wanted and they order then andy made up her mind then the the mcdonald man said that would be twelve fifty and her wallet wasn ' t there what would they do what should i do he wake up he eat breakfast he tie his shoes and he missed the bus he was tar ##dy the boy and girl went to the park and there was a spaceship an alien came out and jessie got mary hand they said let go catch one daniel said no then jessie went over and try 0 ##to catch them they ran she went back home and told their parent the parent came back they went to see if they they are lie or not they weren ' t there that [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] mom said let go out to eat and the kid said mcdonald ##s so they jumped in the car and went to mcdonald ##s the nearest one and the mom and and jacob know what they wanted and they order then andy made up her mind then the the mcdonald man said that would be twelve fifty and her wallet wasn ' t there what would they do what should i do he wake up he eat breakfast he tie his shoes and he missed the bus he was tar ##dy the boy and girl went to the park and there was a spaceship an alien came out and jessie got mary hand they said let go catch one daniel said no then jessie went over and try 0 ##to catch them they ran she went back home and told their parent the parent came back they went to see if they they are lie or not they weren ' t there that [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3566 2056 2292 2175 2041 2000 4521 1998 1996 4845 2056 9383 2015 2061 2027 5598 1999 1996 2482 1998 2253 2000 9383 2015 1996 7205 2028 1998 1996 3566 1998 1998 6213 2113 2054 2027 2359 1998 2027 2344 2059 5557 2081 2039 2014 2568 2059 1996 1996 9383 2158 2056 2008 2052 2022 4376 5595 1998 2014 15882 2347 1005 1056 2045 2054 2052 2027 2079 2054 2323 1045 2079 2002 5256 2039 2002 4521 6350 2002 5495 2010 6007 1998 2002 4771 1996 3902 2002 2001 16985 5149 1996 2879 1998 2611 2253 2000 1996 2380 1998 2045 2001 1037 25516 2019 7344 2234 2041 1998 10934 2288 2984 2192 2027 2056 2292 2175 4608 2028 3817 2056 2053 2059 10934 2253 2058 1998 3046 1014 3406 4608 2068 2027 2743 2016 2253 2067 2188 1998 2409 2037 6687 1996 6687 2234 2067 2027 2253 2000 2156 2065 2027 2027 2024 4682 2030 2025 2027 4694 1005 1056 2045 2008 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3566 2056 2292 2175 2041 2000 4521 1998 1996 4845 2056 9383 2015 2061 2027 5598 1999 1996 2482 1998 2253 2000 9383 2015 1996 7205 2028 1998 1996 3566 1998 1998 6213 2113 2054 2027 2359 1998 2027 2344 2059 5557 2081 2039 2014 2568 2059 1996 1996 9383 2158 2056 2008 2052 2022 4376 5595 1998 2014 15882 2347 1005 1056 2045 2054 2052 2027 2079 2054 2323 1045 2079 2002 5256 2039 2002 4521 6350 2002 5495 2010 6007 1998 2002 4771 1996 3902 2002 2001 16985 5149 1996 2879 1998 2611 2253 2000 1996 2380 1998 2045 2001 1037 25516 2019 7344 2234 2041 1998 10934 2288 2984 2192 2027 2056 2292 2175 4608 2028 3817 2056 2053 2059 10934 2253 2058 1998 3046 1014 3406 4608 2068 2027 2743 2016 2253 2067 2188 1998 2409 2037 6687 1996 6687 2234 2067 2027 2253 2000 2156 2065 2027 2027 2024 4682 2030 2025 2027 4694 1005 1056 2045 2008 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] on tuesday when lisa and raymond got home from school their mother said we are going out to eat where would you like to go lisa and raymond both shouted mcdonald ##s when they got there raymond and his mother knew exactly what they would have raymond would order a cheese ##burg ##er with fries and a large vanilla shake their mother would order a salad when lisa got to the clerk she had decided what she would have she ordered a kids _ meal with coke and chocolate ice + cream the clerk said it would cost eleven fifty when their mother reached for her purse it wasn ' t there she realized she had left it at home on the kitchen counter on wednesday brian ' s alarm clock did not sound so he got up later than he was usually sp ##osta and he was so worried about the time that when he was having breakfast he poured too much milk into his cereal bowl and it spilled out so he had ##ta clean that up and that made him even later then when he was getting dressed and tying his shoes his shoe ##lace broke so he couldn ' t tie his shoe but then he got a spare shoe ##lace from his dad ' s old pair of shoes he made his lunch and put all his homework in his backpack and then ran out the door before he said goodbye to his mom so he sprinted to the bus ##sto ##p where the bus had left right before he got there so he had ##ta walk to school on the way to school he fell in a puddle and was dirty soaking and discouraged when he got to school that mor ##nin it was half an hour after he was sp ##osta get to school one sunday afternoon ryan and megan were hiking in the woods where they found a path of oil and they they tried to follow it but there were many obstacles like large rocks and streams they managed to climb around or over the large rocks and through or over the streams soon after they were done with all the obstacles they found themselves in a green where there was a large picnic table and what seemed to be a landing site then they heard a large roar and looked up there was a flu ##rry of lights and smoke filling the air they ran for the bushes and dove into them soon after a large spacecraft ##ed object landed so they hid behind the bushes and waited soon after they waited for about five minutes and decided to head back once they were about five feet away from the bushes they heard a roar again then suddenly a door opened on the spacecraft which they had noticed by then had some markings on the top they soon after hid behind the bushes once again and saw octopus ##like creatures come out of the space + shuttle they were purple [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] on tuesday when lisa and raymond got home from school their mother said we are going out to eat where would you like to go lisa and raymond both shouted mcdonald ##s when they got there raymond and his mother knew exactly what they would have raymond would order a cheese ##burg ##er with fries and a large vanilla shake their mother would order a salad when lisa got to the clerk she had decided what she would have she ordered a kids _ meal with coke and chocolate ice + cream the clerk said it would cost eleven fifty when their mother reached for her purse it wasn ' t there she realized she had left it at home on the kitchen counter on wednesday brian ' s alarm clock did not sound so he got up later than he was usually sp ##osta and he was so worried about the time that when he was having breakfast he poured too much milk into his cereal bowl and it spilled out so he had ##ta clean that up and that made him even later then when he was getting dressed and tying his shoes his shoe ##lace broke so he couldn ' t tie his shoe but then he got a spare shoe ##lace from his dad ' s old pair of shoes he made his lunch and put all his homework in his backpack and then ran out the door before he said goodbye to his mom so he sprinted to the bus ##sto ##p where the bus had left right before he got there so he had ##ta walk to school on the way to school he fell in a puddle and was dirty soaking and discouraged when he got to school that mor ##nin it was half an hour after he was sp ##osta get to school one sunday afternoon ryan and megan were hiking in the woods where they found a path of oil and they they tried to follow it but there were many obstacles like large rocks and streams they managed to climb around or over the large rocks and through or over the streams soon after they were done with all the obstacles they found themselves in a green where there was a large picnic table and what seemed to be a landing site then they heard a large roar and looked up there was a flu ##rry of lights and smoke filling the air they ran for the bushes and dove into them soon after a large spacecraft ##ed object landed so they hid behind the bushes and waited soon after they waited for about five minutes and decided to head back once they were about five feet away from the bushes they heard a roar again then suddenly a door opened on the spacecraft which they had noticed by then had some markings on the top they soon after hid behind the bushes once again and saw octopus ##like creatures come out of the space + shuttle they were purple [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2006 9857 2043 7059 1998 7638 2288 2188 2013 2082 2037 2388 2056 2057 2024 2183 2041 2000 4521 2073 2052 2017 2066 2000 2175 7059 1998 7638 2119 6626 9383 2015 2043 2027 2288 2045 7638 1998 2010 2388 2354 3599 2054 2027 2052 2031 7638 2052 2344 1037 8808 4645 2121 2007 22201 1998 1037 2312 21161 6073 2037 2388 2052 2344 1037 16521 2043 7059 2288 2000 1996 7805 2016 2018 2787 2054 2016 2052 2031 2016 3641 1037 4268 1035 7954 2007 14492 1998 7967 3256 1009 6949 1996 7805 2056 2009 2052 3465 5408 5595 2043 2037 2388 2584 2005 2014 8722 2009 2347 1005 1056 2045 2016 3651 2016 2018 2187 2009 2012 2188 2006 1996 3829 4675 2006 9317 4422 1005 1055 8598 5119 2106 2025 2614 2061 2002 2288 2039 2101 2084 2002 2001 2788 11867 28696 1998 2002 2001 2061 5191 2055 1996 2051 2008 2043 2002 2001 2383 6350 2002 8542 2205 2172 6501 2046 2010 20943 4605 1998 2009 13439 2041 2061 2002 2018 2696 4550 2008 2039 1998 2008 2081 2032 2130 2101 2059 2043 2002 2001 2893 5102 1998 15233 2010 6007 2010 10818 19217 3631 2061 2002 2481 1005 1056 5495 2010 10818 2021 2059 2002 2288 1037 8622 10818 19217 2013 2010 3611 1005 1055 2214 3940 1997 6007 2002 2081 2010 6265 1998 2404 2035 2010 19453 1999 2010 13383 1998 2059 2743 2041 1996 2341 2077 2002 2056 9119 2000 2010 3566 2061 2002 25156 2000 1996 3902 16033 2361 2073 1996 3902 2018 2187 2157 2077 2002 2288 2045 2061 2002 2018 2696 3328 2000 2082 2006 1996 2126 2000 2082 2002 3062 1999 1037 25081 1998 2001 6530 22721 1998 22585 2043 2002 2288 2000 2082 2008 22822 11483 2009 2001 2431 2019 3178 2044 2002 2001 11867 28696 2131 2000 2082 2028 4465 5027 4575 1998 12756 2020 13039 1999 1996 5249 2073 2027 2179 1037 4130 1997 3514 1998 2027 2027 2699 2000 3582 2009 2021 2045 2020 2116 15314 2066 2312 5749 1998 9199 2027 3266 2000 7105 2105 2030 2058 1996 2312 5749 1998 2083 2030 2058 1996 9199 2574 2044 2027 2020 2589 2007 2035 1996 15314 2027 2179 3209 1999 1037 2665 2073 2045 2001 1037 2312 12695 2795 1998 2054 2790 2000 2022 1037 4899 2609 2059 2027 2657 1037 2312 11950 1998 2246 2039 2045 2001 1037 19857 12244 1997 4597 1998 5610 8110 1996 2250 2027 2743 2005 1996 14568 1998 10855 2046 2068 2574 2044 1037 2312 12076 2098 4874 5565 2061 2027 11041 2369 1996 14568 1998 4741 2574 2044 2027 4741 2005 2055 2274 2781 1998 2787 2000 2132 2067 2320 2027 2020 2055 2274 2519 2185 2013 1996 14568 2027 2657 1037 11950 2153 2059 3402 1037 2341 2441 2006 1996 12076 2029 2027 2018 4384 2011 2059 2018 2070 13967 2006 1996 2327 2027 2574 2044 11041 2369 1996 14568 2320 2153 1998 2387 24318 10359 7329 2272 2041 1997 1996 2686 1009 10382 2027 2020 6379 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2006 9857 2043 7059 1998 7638 2288 2188 2013 2082 2037 2388 2056 2057 2024 2183 2041 2000 4521 2073 2052 2017 2066 2000 2175 7059 1998 7638 2119 6626 9383 2015 2043 2027 2288 2045 7638 1998 2010 2388 2354 3599 2054 2027 2052 2031 7638 2052 2344 1037 8808 4645 2121 2007 22201 1998 1037 2312 21161 6073 2037 2388 2052 2344 1037 16521 2043 7059 2288 2000 1996 7805 2016 2018 2787 2054 2016 2052 2031 2016 3641 1037 4268 1035 7954 2007 14492 1998 7967 3256 1009 6949 1996 7805 2056 2009 2052 3465 5408 5595 2043 2037 2388 2584 2005 2014 8722 2009 2347 1005 1056 2045 2016 3651 2016 2018 2187 2009 2012 2188 2006 1996 3829 4675 2006 9317 4422 1005 1055 8598 5119 2106 2025 2614 2061 2002 2288 2039 2101 2084 2002 2001 2788 11867 28696 1998 2002 2001 2061 5191 2055 1996 2051 2008 2043 2002 2001 2383 6350 2002 8542 2205 2172 6501 2046 2010 20943 4605 1998 2009 13439 2041 2061 2002 2018 2696 4550 2008 2039 1998 2008 2081 2032 2130 2101 2059 2043 2002 2001 2893 5102 1998 15233 2010 6007 2010 10818 19217 3631 2061 2002 2481 1005 1056 5495 2010 10818 2021 2059 2002 2288 1037 8622 10818 19217 2013 2010 3611 1005 1055 2214 3940 1997 6007 2002 2081 2010 6265 1998 2404 2035 2010 19453 1999 2010 13383 1998 2059 2743 2041 1996 2341 2077 2002 2056 9119 2000 2010 3566 2061 2002 25156 2000 1996 3902 16033 2361 2073 1996 3902 2018 2187 2157 2077 2002 2288 2045 2061 2002 2018 2696 3328 2000 2082 2006 1996 2126 2000 2082 2002 3062 1999 1037 25081 1998 2001 6530 22721 1998 22585 2043 2002 2288 2000 2082 2008 22822 11483 2009 2001 2431 2019 3178 2044 2002 2001 11867 28696 2131 2000 2082 2028 4465 5027 4575 1998 12756 2020 13039 1999 1996 5249 2073 2027 2179 1037 4130 1997 3514 1998 2027 2027 2699 2000 3582 2009 2021 2045 2020 2116 15314 2066 2312 5749 1998 9199 2027 3266 2000 7105 2105 2030 2058 1996 2312 5749 1998 2083 2030 2058 1996 9199 2574 2044 2027 2020 2589 2007 2035 1996 15314 2027 2179 3209 1999 1037 2665 2073 2045 2001 1037 2312 12695 2795 1998 2054 2790 2000 2022 1037 4899 2609 2059 2027 2657 1037 2312 11950 1998 2246 2039 2045 2001 1037 19857 12244 1997 4597 1998 5610 8110 1996 2250 2027 2743 2005 1996 14568 1998 10855 2046 2068 2574 2044 1037 2312 12076 2098 4874 5565 2061 2027 11041 2369 1996 14568 1998 4741 2574 2044 2027 4741 2005 2055 2274 2781 1998 2787 2000 2132 2067 2320 2027 2020 2055 2274 2519 2185 2013 1996 14568 2027 2657 1037 11950 2153 2059 3402 1037 2341 2441 2006 1996 12076 2029 2027 2018 4384 2011 2059 2018 2070 13967 2006 1996 2327 2027 2574 2044 11041 2369 1996 14568 2320 2153 1998 2387 24318 10359 7329 2272 2041 1997 1996 2686 1009 10382 2027 2020 6379 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the mom asked where do you guys wanna go and they both named mcdonald ##s so the mom took them there and lisa know what she wanted a big _ mac or a other little hamburger and the boy he he picked hamburger french fries and a milk ##sha ##ke chocolate one and the mom ordered hamburger pop and french fries and the girl lisa ordered french fries pop hamburger and milk ##sha ##ke what ' s that one kind i said i don ' t either then the guy said it would be twelve ninety nine and the mom reached down and her purse wasn ' t there instead she remembered where she put it it was at home on her desk counter i mean counter what ' s his name though a boy woke up and out of bed and he looked at his clock and it was late and he dropped some milk all over the ground because he wasn ' t even looking at it then he put on his shoes and his shoes ##tri ##ng ripped and then he he got out of his house and missed the bus and then he was late to class and the teacher was pointing at her time i don ' t know where to start the beginning of the book you always give me the hard ones i don ' t know aliens come down can you think of anything else hi and they have eight legs there ' s a girl indian mom indian and a dad indian and two two normal people and the the girl she went to go say hi but the boy normal one didn ' t let her pulled her back said stop and the indians had a dog [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the mom asked where do you guys wanna go and they both named mcdonald ##s so the mom took them there and lisa know what she wanted a big _ mac or a other little hamburger and the boy he he picked hamburger french fries and a milk ##sha ##ke chocolate one and the mom ordered hamburger pop and french fries and the girl lisa ordered french fries pop hamburger and milk ##sha ##ke what ' s that one kind i said i don ' t either then the guy said it would be twelve ninety nine and the mom reached down and her purse wasn ' t there instead she remembered where she put it it was at home on her desk counter i mean counter what ' s his name though a boy woke up and out of bed and he looked at his clock and it was late and he dropped some milk all over the ground because he wasn ' t even looking at it then he put on his shoes and his shoes ##tri ##ng ripped and then he he got out of his house and missed the bus and then he was late to class and the teacher was pointing at her time i don ' t know where to start the beginning of the book you always give me the hard ones i don ' t know aliens come down can you think of anything else hi and they have eight legs there ' s a girl indian mom indian and a dad indian and two two normal people and the the girl she went to go say hi but the boy normal one didn ' t let her pulled her back said stop and the indians had a dog [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3566 2356 2073 2079 2017 4364 10587 2175 1998 2027 2119 2315 9383 2015 2061 1996 3566 2165 2068 2045 1998 7059 2113 2054 2016 2359 1037 2502 1035 6097 2030 1037 2060 2210 24575 1998 1996 2879 2002 2002 3856 24575 2413 22201 1998 1037 6501 7377 3489 7967 2028 1998 1996 3566 3641 24575 3769 1998 2413 22201 1998 1996 2611 7059 3641 2413 22201 3769 24575 1998 6501 7377 3489 2054 1005 1055 2008 2028 2785 1045 2056 1045 2123 1005 1056 2593 2059 1996 3124 2056 2009 2052 2022 4376 13568 3157 1998 1996 3566 2584 2091 1998 2014 8722 2347 1005 1056 2045 2612 2016 4622 2073 2016 2404 2009 2009 2001 2012 2188 2006 2014 4624 4675 1045 2812 4675 2054 1005 1055 2010 2171 2295 1037 2879 8271 2039 1998 2041 1997 2793 1998 2002 2246 2012 2010 5119 1998 2009 2001 2397 1998 2002 3333 2070 6501 2035 2058 1996 2598 2138 2002 2347 1005 1056 2130 2559 2012 2009 2059 2002 2404 2006 2010 6007 1998 2010 6007 18886 3070 9157 1998 2059 2002 2002 2288 2041 1997 2010 2160 1998 4771 1996 3902 1998 2059 2002 2001 2397 2000 2465 1998 1996 3836 2001 7302 2012 2014 2051 1045 2123 1005 1056 2113 2073 2000 2707 1996 2927 1997 1996 2338 2017 2467 2507 2033 1996 2524 3924 1045 2123 1005 1056 2113 12114 2272 2091 2064 2017 2228 1997 2505 2842 7632 1998 2027 2031 2809 3456 2045 1005 1055 1037 2611 2796 3566 2796 1998 1037 3611 2796 1998 2048 2048 3671 2111 1998 1996 1996 2611 2016 2253 2000 2175 2360 7632 2021 1996 2879 3671 2028 2134 1005 1056 2292 2014 2766 2014 2067 2056 2644 1998 1996 6505 2018 1037 3899 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3566 2356 2073 2079 2017 4364 10587 2175 1998 2027 2119 2315 9383 2015 2061 1996 3566 2165 2068 2045 1998 7059 2113 2054 2016 2359 1037 2502 1035 6097 2030 1037 2060 2210 24575 1998 1996 2879 2002 2002 3856 24575 2413 22201 1998 1037 6501 7377 3489 7967 2028 1998 1996 3566 3641 24575 3769 1998 2413 22201 1998 1996 2611 7059 3641 2413 22201 3769 24575 1998 6501 7377 3489 2054 1005 1055 2008 2028 2785 1045 2056 1045 2123 1005 1056 2593 2059 1996 3124 2056 2009 2052 2022 4376 13568 3157 1998 1996 3566 2584 2091 1998 2014 8722 2347 1005 1056 2045 2612 2016 4622 2073 2016 2404 2009 2009 2001 2012 2188 2006 2014 4624 4675 1045 2812 4675 2054 1005 1055 2010 2171 2295 1037 2879 8271 2039 1998 2041 1997 2793 1998 2002 2246 2012 2010 5119 1998 2009 2001 2397 1998 2002 3333 2070 6501 2035 2058 1996 2598 2138 2002 2347 1005 1056 2130 2559 2012 2009 2059 2002 2404 2006 2010 6007 1998 2010 6007 18886 3070 9157 1998 2059 2002 2002 2288 2041 1997 2010 2160 1998 4771 1996 3902 1998 2059 2002 2001 2397 2000 2465 1998 1996 3836 2001 7302 2012 2014 2051 1045 2123 1005 1056 2113 2073 2000 2707 1996 2927 1997 1996 2338 2017 2467 2507 2033 1996 2524 3924 1045 2123 1005 1056 2113 12114 2272 2091 2064 2017 2228 1997 2505 2842 7632 1998 2027 2031 2809 3456 2045 1005 1055 1037 2611 2796 3566 2796 1998 1037 3611 2796 1998 2048 2048 3671 2111 1998 1996 1996 2611 2016 2253 2000 2175 2360 7632 2021 1996 2879 3671 2028 2134 1005 1056 2292 2014 2766 2014 2067 2056 2644 1998 1996 6505 2018 1037 3899 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 209\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] they are playing with a ball pause1 and they are at the pool pause2 and pause1 it fell in the water pause1 and then pause1 the gi ##raf ##fe swim ##med and got it and then he passed it to the elephant pause1 and then she is standing all pretty pause1 they are at the swimming pool and they were just getting ready to do something and the gi ##raf ##fe is chasing the elephant and the elephant slips and he gets his knee scraped and then the life ##guard runs pause1 and comes to put a banda ##id on it and then the banda ##id was on and she felt okay and she was sitting on the bench they were playing airplane pause1 and they were zoom ##ing it around and then the elephant took it from the gi ##raf ##fe pause1 and then she accidentally threw it in the water and then the gi ##raf ##fe got really mad pause1 and then the life ##guard came pause1 and he did not know how to get it out he tried to reach it pause1 and pause1 he did not know what to do still pause1 and then the lady life ##guard came and then she took it out with the thing that you catch fish with and then pause1 she gave it back to the gi ##raf ##fe and then he hugged it they were getting ready to build a sand ##castle in their sand ##box and they already built one pause1 on the other side and they were putting sand in the shovel pause1 and they dumped it all over the the sand ##castle and it all came into a pile of sand pause1 and they were crying they went out for a picnic pause1 and they ate lots of food pause1 and then they got full pause1 and then the bunny did not eat any more pause1 and then the doctor came over pause2 and the dogg ##y pulled her over to where pause1 the bunny is pause1 and the doctor is trying to get the bunny better pause1 and then pause1 he is all better again they have a wagon with a balloon on it and pause1 they are pointing at the balloon and then they tie it on better and then it falls off the wagon and they try to catch it and pause2 one got really mad and one got really sad and then they saw a guy with balloons and then they asked for one and then they did not get enough money and then pause2 they see him again pause1 and they see the doctor pause1 and the bunny tells the doctor where the balloons are and then the doctor gives the man money and then they all get a balloon [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] they are playing with a ball pause1 and they are at the pool pause2 and pause1 it fell in the water pause1 and then pause1 the gi ##raf ##fe swim ##med and got it and then he passed it to the elephant pause1 and then she is standing all pretty pause1 they are at the swimming pool and they were just getting ready to do something and the gi ##raf ##fe is chasing the elephant and the elephant slips and he gets his knee scraped and then the life ##guard runs pause1 and comes to put a banda ##id on it and then the banda ##id was on and she felt okay and she was sitting on the bench they were playing airplane pause1 and they were zoom ##ing it around and then the elephant took it from the gi ##raf ##fe pause1 and then she accidentally threw it in the water and then the gi ##raf ##fe got really mad pause1 and then the life ##guard came pause1 and he did not know how to get it out he tried to reach it pause1 and pause1 he did not know what to do still pause1 and then the lady life ##guard came and then she took it out with the thing that you catch fish with and then pause1 she gave it back to the gi ##raf ##fe and then he hugged it they were getting ready to build a sand ##castle in their sand ##box and they already built one pause1 on the other side and they were putting sand in the shovel pause1 and they dumped it all over the the sand ##castle and it all came into a pile of sand pause1 and they were crying they went out for a picnic pause1 and they ate lots of food pause1 and then they got full pause1 and then the bunny did not eat any more pause1 and then the doctor came over pause2 and the dogg ##y pulled her over to where pause1 the bunny is pause1 and the doctor is trying to get the bunny better pause1 and then pause1 he is all better again they have a wagon with a balloon on it and pause1 they are pointing at the balloon and then they tie it on better and then it falls off the wagon and they try to catch it and pause2 one got really mad and one got really sad and then they saw a guy with balloons and then they asked for one and then they did not get enough money and then pause2 they see him again pause1 and they see the doctor pause1 and the bunny tells the doctor where the balloons are and then the doctor gives the man money and then they all get a balloon [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2027 2024 2652 2007 1037 3608 1 1998 2027 2024 2012 1996 4770 2 1998 1 2009 3062 1999 1996 2300 1 1998 2059 1 1996 21025 27528 7959 9880 7583 1998 2288 2009 1998 2059 2002 2979 2009 2000 1996 10777 1 1998 2059 2016 2003 3061 2035 3492 1 2027 2024 2012 1996 5742 4770 1998 2027 2020 2074 2893 3201 2000 2079 2242 1998 1996 21025 27528 7959 2003 11777 1996 10777 1998 1996 10777 17433 1998 2002 4152 2010 6181 20378 1998 2059 1996 2166 18405 3216 1 1998 3310 2000 2404 1037 24112 3593 2006 2009 1998 2059 1996 24112 3593 2001 2006 1998 2016 2371 3100 1998 2016 2001 3564 2006 1996 6847 2027 2020 2652 13297 1 1998 2027 2020 24095 2075 2009 2105 1998 2059 1996 10777 2165 2009 2013 1996 21025 27528 7959 1 1998 2059 2016 9554 4711 2009 1999 1996 2300 1998 2059 1996 21025 27528 7959 2288 2428 5506 1 1998 2059 1996 2166 18405 2234 1 1998 2002 2106 2025 2113 2129 2000 2131 2009 2041 2002 2699 2000 3362 2009 1 1998 1 2002 2106 2025 2113 2054 2000 2079 2145 1 1998 2059 1996 3203 2166 18405 2234 1998 2059 2016 2165 2009 2041 2007 1996 2518 2008 2017 4608 3869 2007 1998 2059 1 2016 2435 2009 2067 2000 1996 21025 27528 7959 1998 2059 2002 10308 2009 2027 2020 2893 3201 2000 3857 1037 5472 23662 1999 2037 5472 8758 1998 2027 2525 2328 2028 1 2006 1996 2060 2217 1998 2027 2020 5128 5472 1999 1996 24596 1 1998 2027 14019 2009 2035 2058 1996 1996 5472 23662 1998 2009 2035 2234 2046 1037 8632 1997 5472 1 1998 2027 2020 6933 2027 2253 2041 2005 1037 12695 1 1998 2027 8823 7167 1997 2833 1 1998 2059 2027 2288 2440 1 1998 2059 1996 16291 2106 2025 4521 2151 2062 1 1998 2059 1996 3460 2234 2058 2 1998 1996 28844 2100 2766 2014 2058 2000 2073 1 1996 16291 2003 1 1998 1996 3460 2003 2667 2000 2131 1996 16291 2488 1 1998 2059 1 2002 2003 2035 2488 2153 2027 2031 1037 9540 2007 1037 13212 2006 2009 1998 1 2027 2024 7302 2012 1996 13212 1998 2059 2027 5495 2009 2006 2488 1998 2059 2009 4212 2125 1996 9540 1998 2027 3046 2000 4608 2009 1998 2 2028 2288 2428 5506 1998 2028 2288 2428 6517 1998 2059 2027 2387 1037 3124 2007 22163 1998 2059 2027 2356 2005 2028 1998 2059 2027 2106 2025 2131 2438 2769 1998 2059 2 2027 2156 2032 2153 1 1998 2027 2156 1996 3460 1 1998 1996 16291 4136 1996 3460 2073 1996 22163 2024 1998 2059 1996 3460 3957 1996 2158 2769 1998 2059 2027 2035 2131 1037 13212 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2027 2024 2652 2007 1037 3608 1 1998 2027 2024 2012 1996 4770 2 1998 1 2009 3062 1999 1996 2300 1 1998 2059 1 1996 21025 27528 7959 9880 7583 1998 2288 2009 1998 2059 2002 2979 2009 2000 1996 10777 1 1998 2059 2016 2003 3061 2035 3492 1 2027 2024 2012 1996 5742 4770 1998 2027 2020 2074 2893 3201 2000 2079 2242 1998 1996 21025 27528 7959 2003 11777 1996 10777 1998 1996 10777 17433 1998 2002 4152 2010 6181 20378 1998 2059 1996 2166 18405 3216 1 1998 3310 2000 2404 1037 24112 3593 2006 2009 1998 2059 1996 24112 3593 2001 2006 1998 2016 2371 3100 1998 2016 2001 3564 2006 1996 6847 2027 2020 2652 13297 1 1998 2027 2020 24095 2075 2009 2105 1998 2059 1996 10777 2165 2009 2013 1996 21025 27528 7959 1 1998 2059 2016 9554 4711 2009 1999 1996 2300 1998 2059 1996 21025 27528 7959 2288 2428 5506 1 1998 2059 1996 2166 18405 2234 1 1998 2002 2106 2025 2113 2129 2000 2131 2009 2041 2002 2699 2000 3362 2009 1 1998 1 2002 2106 2025 2113 2054 2000 2079 2145 1 1998 2059 1996 3203 2166 18405 2234 1998 2059 2016 2165 2009 2041 2007 1996 2518 2008 2017 4608 3869 2007 1998 2059 1 2016 2435 2009 2067 2000 1996 21025 27528 7959 1998 2059 2002 10308 2009 2027 2020 2893 3201 2000 3857 1037 5472 23662 1999 2037 5472 8758 1998 2027 2525 2328 2028 1 2006 1996 2060 2217 1998 2027 2020 5128 5472 1999 1996 24596 1 1998 2027 14019 2009 2035 2058 1996 1996 5472 23662 1998 2009 2035 2234 2046 1037 8632 1997 5472 1 1998 2027 2020 6933 2027 2253 2041 2005 1037 12695 1 1998 2027 8823 7167 1997 2833 1 1998 2059 2027 2288 2440 1 1998 2059 1996 16291 2106 2025 4521 2151 2062 1 1998 2059 1996 3460 2234 2058 2 1998 1996 28844 2100 2766 2014 2058 2000 2073 1 1996 16291 2003 1 1998 1996 3460 2003 2667 2000 2131 1996 16291 2488 1 1998 2059 1 2002 2003 2035 2488 2153 2027 2031 1037 9540 2007 1037 13212 2006 2009 1998 1 2027 2024 7302 2012 1996 13212 1998 2059 2027 5495 2009 2006 2488 1998 2059 2009 4212 2125 1996 9540 1998 2027 3046 2000 4608 2009 1998 2 2028 2288 2428 5506 1998 2028 2288 2428 6517 1998 2059 2027 2387 1037 3124 2007 22163 1998 2059 2027 2356 2005 2028 1998 2059 2027 2106 2025 2131 2438 2769 1998 2059 2 2027 2156 2032 2153 1 1998 2027 2156 1996 3460 1 1998 1996 16291 4136 1996 3460 2073 1996 22163 2024 1998 2059 1996 3460 3957 1996 2158 2769 1998 2059 2027 2035 2131 1037 13212 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] they went to mcdonald ##s and their mother forgot her purse well the boy and the girl wanted to go to mcdonald ##s at the beginning and actually at the beginning the mother said where do you wanna go out to eat and the boy and the girl said mcdonald ##s they both said and then after that they went off in the car to go to mcdonald ##s and once they arrived there everybody ordered something and then the mom reached for the purse and she figured out that her purse was at home okay first i was getting up from bed and i figured out that it was time to go to school so i went into the kitchen and then i made a big mess out of the milk and everything else and i was just looking at the time and so after that i was very frustrated so i broke my lace on my shoe and then once i got outside the bus is already left and so i had ##ta walk to school and i didn ' t make it to school on time once upon a time there were a boy and girl they were both brother and sisters they were trying to go down to the park for a family picnic but once they got there they saw an alien spaceship so they saw a dog alien a little boy alien a mom and a dad alien and a sister alien and then her brother said don ' t go don ' t go because those are aliens you don ' t know what they can do but she wanted to go so she said come on come on it ' s time to go we gotta go look and so at the end the brother won and they went back to go tell their parents and then they came back and saw the aliens and then they believed them and then the parents faint ##ed and once they awoke they went back home and called the police and asked them to get these aliens off the park and then once the police came they saw nothing that ' s it [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] they went to mcdonald ##s and their mother forgot her purse well the boy and the girl wanted to go to mcdonald ##s at the beginning and actually at the beginning the mother said where do you wanna go out to eat and the boy and the girl said mcdonald ##s they both said and then after that they went off in the car to go to mcdonald ##s and once they arrived there everybody ordered something and then the mom reached for the purse and she figured out that her purse was at home okay first i was getting up from bed and i figured out that it was time to go to school so i went into the kitchen and then i made a big mess out of the milk and everything else and i was just looking at the time and so after that i was very frustrated so i broke my lace on my shoe and then once i got outside the bus is already left and so i had ##ta walk to school and i didn ' t make it to school on time once upon a time there were a boy and girl they were both brother and sisters they were trying to go down to the park for a family picnic but once they got there they saw an alien spaceship so they saw a dog alien a little boy alien a mom and a dad alien and a sister alien and then her brother said don ' t go don ' t go because those are aliens you don ' t know what they can do but she wanted to go so she said come on come on it ' s time to go we gotta go look and so at the end the brother won and they went back to go tell their parents and then they came back and saw the aliens and then they believed them and then the parents faint ##ed and once they awoke they went back home and called the police and asked them to get these aliens off the park and then once the police came they saw nothing that ' s it [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2027 2253 2000 9383 2015 1998 2037 2388 9471 2014 8722 2092 1996 2879 1998 1996 2611 2359 2000 2175 2000 9383 2015 2012 1996 2927 1998 2941 2012 1996 2927 1996 2388 2056 2073 2079 2017 10587 2175 2041 2000 4521 1998 1996 2879 1998 1996 2611 2056 9383 2015 2027 2119 2056 1998 2059 2044 2008 2027 2253 2125 1999 1996 2482 2000 2175 2000 9383 2015 1998 2320 2027 3369 2045 7955 3641 2242 1998 2059 1996 3566 2584 2005 1996 8722 1998 2016 6618 2041 2008 2014 8722 2001 2012 2188 3100 2034 1045 2001 2893 2039 2013 2793 1998 1045 6618 2041 2008 2009 2001 2051 2000 2175 2000 2082 2061 1045 2253 2046 1996 3829 1998 2059 1045 2081 1037 2502 6752 2041 1997 1996 6501 1998 2673 2842 1998 1045 2001 2074 2559 2012 1996 2051 1998 2061 2044 2008 1045 2001 2200 10206 2061 1045 3631 2026 12922 2006 2026 10818 1998 2059 2320 1045 2288 2648 1996 3902 2003 2525 2187 1998 2061 1045 2018 2696 3328 2000 2082 1998 1045 2134 1005 1056 2191 2009 2000 2082 2006 2051 2320 2588 1037 2051 2045 2020 1037 2879 1998 2611 2027 2020 2119 2567 1998 5208 2027 2020 2667 2000 2175 2091 2000 1996 2380 2005 1037 2155 12695 2021 2320 2027 2288 2045 2027 2387 2019 7344 25516 2061 2027 2387 1037 3899 7344 1037 2210 2879 7344 1037 3566 1998 1037 3611 7344 1998 1037 2905 7344 1998 2059 2014 2567 2056 2123 1005 1056 2175 2123 1005 1056 2175 2138 2216 2024 12114 2017 2123 1005 1056 2113 2054 2027 2064 2079 2021 2016 2359 2000 2175 2061 2016 2056 2272 2006 2272 2006 2009 1005 1055 2051 2000 2175 2057 10657 2175 2298 1998 2061 2012 1996 2203 1996 2567 2180 1998 2027 2253 2067 2000 2175 2425 2037 3008 1998 2059 2027 2234 2067 1998 2387 1996 12114 1998 2059 2027 3373 2068 1998 2059 1996 3008 8143 2098 1998 2320 2027 19179 2027 2253 2067 2188 1998 2170 1996 2610 1998 2356 2068 2000 2131 2122 12114 2125 1996 2380 1998 2059 2320 1996 2610 2234 2027 2387 2498 2008 1005 1055 2009 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2027 2253 2000 9383 2015 1998 2037 2388 9471 2014 8722 2092 1996 2879 1998 1996 2611 2359 2000 2175 2000 9383 2015 2012 1996 2927 1998 2941 2012 1996 2927 1996 2388 2056 2073 2079 2017 10587 2175 2041 2000 4521 1998 1996 2879 1998 1996 2611 2056 9383 2015 2027 2119 2056 1998 2059 2044 2008 2027 2253 2125 1999 1996 2482 2000 2175 2000 9383 2015 1998 2320 2027 3369 2045 7955 3641 2242 1998 2059 1996 3566 2584 2005 1996 8722 1998 2016 6618 2041 2008 2014 8722 2001 2012 2188 3100 2034 1045 2001 2893 2039 2013 2793 1998 1045 6618 2041 2008 2009 2001 2051 2000 2175 2000 2082 2061 1045 2253 2046 1996 3829 1998 2059 1045 2081 1037 2502 6752 2041 1997 1996 6501 1998 2673 2842 1998 1045 2001 2074 2559 2012 1996 2051 1998 2061 2044 2008 1045 2001 2200 10206 2061 1045 3631 2026 12922 2006 2026 10818 1998 2059 2320 1045 2288 2648 1996 3902 2003 2525 2187 1998 2061 1045 2018 2696 3328 2000 2082 1998 1045 2134 1005 1056 2191 2009 2000 2082 2006 2051 2320 2588 1037 2051 2045 2020 1037 2879 1998 2611 2027 2020 2119 2567 1998 5208 2027 2020 2667 2000 2175 2091 2000 1996 2380 2005 1037 2155 12695 2021 2320 2027 2288 2045 2027 2387 2019 7344 25516 2061 2027 2387 1037 3899 7344 1037 2210 2879 7344 1037 3566 1998 1037 3611 7344 1998 1037 2905 7344 1998 2059 2014 2567 2056 2123 1005 1056 2175 2123 1005 1056 2175 2138 2216 2024 12114 2017 2123 1005 1056 2113 2054 2027 2064 2079 2021 2016 2359 2000 2175 2061 2016 2056 2272 2006 2272 2006 2009 1005 1055 2051 2000 2175 2057 10657 2175 2298 1998 2061 2012 1996 2203 1996 2567 2180 1998 2027 2253 2067 2000 2175 2425 2037 3008 1998 2059 2027 2234 2067 1998 2387 1996 12114 1998 2059 2027 3373 2068 1998 2059 1996 3008 8143 2098 1998 2320 2027 19179 2027 2253 2067 2188 1998 2170 1996 2610 1998 2356 2068 2000 2131 2122 12114 2125 1996 2380 1998 2059 2320 1996 2610 2234 2027 2387 2498 2008 1005 1055 2009 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] once there were a boy and a girl their names were lisa and raymond when they got home from school their mother told them we are going out to eat where would you like to go they both shouted out mcdonald ##s so they ran and hoped in the car and they were on their way to mcdonald ##s raymond and their mom both decided what they wanted already but lisa did not know then she finally made up her mind and told the clerk i wanna happy ##me ##al with a drink please and then the clerk said that ' ll be twelve fifty and then her mom reached to get her purse and she did not have the purse it was on the counter at home what should they do there once was a boy getting up out of bed his clock started ringing he shut it off went downstairs and had breakfast he poured the cereal then the milk but the milk spilled and made a mess then he went to put on his shoes the shoes ##tri ##ng ##s broke so he tried to fix it after that he put on his sneakers and he went to the bus ##sto ##p the bus was already gone he had ##ta go chase after it and pretty soon the teacher said he was late for school there once were two children named melissa and corbin they were hiking on a mountain once and they saw something in the sky it landed close to them they ran behind a bush and peaked 0 corbin was a scared ##y ##cat to see melissa was brave so melissa pulled corbin but he stayed still he would not go then it opened all of the sudden a family was coming out a girl alien a dog alien a mother alien a dad alien and a brother alien was still in the shuttle the dog was sniffing them and went towards them they saw them and they were scared they said what do you want with us nothing we just came to visit your planet we ' re not trying to take anything a couple days after that they were robin ##g stores so they lied so they learned don ' t lie [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] once there were a boy and a girl their names were lisa and raymond when they got home from school their mother told them we are going out to eat where would you like to go they both shouted out mcdonald ##s so they ran and hoped in the car and they were on their way to mcdonald ##s raymond and their mom both decided what they wanted already but lisa did not know then she finally made up her mind and told the clerk i wanna happy ##me ##al with a drink please and then the clerk said that ' ll be twelve fifty and then her mom reached to get her purse and she did not have the purse it was on the counter at home what should they do there once was a boy getting up out of bed his clock started ringing he shut it off went downstairs and had breakfast he poured the cereal then the milk but the milk spilled and made a mess then he went to put on his shoes the shoes ##tri ##ng ##s broke so he tried to fix it after that he put on his sneakers and he went to the bus ##sto ##p the bus was already gone he had ##ta go chase after it and pretty soon the teacher said he was late for school there once were two children named melissa and corbin they were hiking on a mountain once and they saw something in the sky it landed close to them they ran behind a bush and peaked 0 corbin was a scared ##y ##cat to see melissa was brave so melissa pulled corbin but he stayed still he would not go then it opened all of the sudden a family was coming out a girl alien a dog alien a mother alien a dad alien and a brother alien was still in the shuttle the dog was sniffing them and went towards them they saw them and they were scared they said what do you want with us nothing we just came to visit your planet we ' re not trying to take anything a couple days after that they were robin ##g stores so they lied so they learned don ' t lie [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2320 2045 2020 1037 2879 1998 1037 2611 2037 3415 2020 7059 1998 7638 2043 2027 2288 2188 2013 2082 2037 2388 2409 2068 2057 2024 2183 2041 2000 4521 2073 2052 2017 2066 2000 2175 2027 2119 6626 2041 9383 2015 2061 2027 2743 1998 5113 1999 1996 2482 1998 2027 2020 2006 2037 2126 2000 9383 2015 7638 1998 2037 3566 2119 2787 2054 2027 2359 2525 2021 7059 2106 2025 2113 2059 2016 2633 2081 2039 2014 2568 1998 2409 1996 7805 1045 10587 3407 4168 2389 2007 1037 4392 3531 1998 2059 1996 7805 2056 2008 1005 2222 2022 4376 5595 1998 2059 2014 3566 2584 2000 2131 2014 8722 1998 2016 2106 2025 2031 1996 8722 2009 2001 2006 1996 4675 2012 2188 2054 2323 2027 2079 2045 2320 2001 1037 2879 2893 2039 2041 1997 2793 2010 5119 2318 13060 2002 3844 2009 2125 2253 10025 1998 2018 6350 2002 8542 1996 20943 2059 1996 6501 2021 1996 6501 13439 1998 2081 1037 6752 2059 2002 2253 2000 2404 2006 2010 6007 1996 6007 18886 3070 2015 3631 2061 2002 2699 2000 8081 2009 2044 2008 2002 2404 2006 2010 28130 1998 2002 2253 2000 1996 3902 16033 2361 1996 3902 2001 2525 2908 2002 2018 2696 2175 5252 2044 2009 1998 3492 2574 1996 3836 2056 2002 2001 2397 2005 2082 2045 2320 2020 2048 2336 2315 9606 1998 24003 2027 2020 13039 2006 1037 3137 2320 1998 2027 2387 2242 1999 1996 3712 2009 5565 2485 2000 2068 2027 2743 2369 1037 5747 1998 6601 1014 24003 2001 1037 6015 2100 11266 2000 2156 9606 2001 9191 2061 9606 2766 24003 2021 2002 4370 2145 2002 2052 2025 2175 2059 2009 2441 2035 1997 1996 5573 1037 2155 2001 2746 2041 1037 2611 7344 1037 3899 7344 1037 2388 7344 1037 3611 7344 1998 1037 2567 7344 2001 2145 1999 1996 10382 1996 3899 2001 27646 2068 1998 2253 2875 2068 2027 2387 2068 1998 2027 2020 6015 2027 2056 2054 2079 2017 2215 2007 2149 2498 2057 2074 2234 2000 3942 2115 4774 2057 1005 2128 2025 2667 2000 2202 2505 1037 3232 2420 2044 2008 2027 2020 5863 2290 5324 2061 2027 9828 2061 2027 4342 2123 1005 1056 4682 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2320 2045 2020 1037 2879 1998 1037 2611 2037 3415 2020 7059 1998 7638 2043 2027 2288 2188 2013 2082 2037 2388 2409 2068 2057 2024 2183 2041 2000 4521 2073 2052 2017 2066 2000 2175 2027 2119 6626 2041 9383 2015 2061 2027 2743 1998 5113 1999 1996 2482 1998 2027 2020 2006 2037 2126 2000 9383 2015 7638 1998 2037 3566 2119 2787 2054 2027 2359 2525 2021 7059 2106 2025 2113 2059 2016 2633 2081 2039 2014 2568 1998 2409 1996 7805 1045 10587 3407 4168 2389 2007 1037 4392 3531 1998 2059 1996 7805 2056 2008 1005 2222 2022 4376 5595 1998 2059 2014 3566 2584 2000 2131 2014 8722 1998 2016 2106 2025 2031 1996 8722 2009 2001 2006 1996 4675 2012 2188 2054 2323 2027 2079 2045 2320 2001 1037 2879 2893 2039 2041 1997 2793 2010 5119 2318 13060 2002 3844 2009 2125 2253 10025 1998 2018 6350 2002 8542 1996 20943 2059 1996 6501 2021 1996 6501 13439 1998 2081 1037 6752 2059 2002 2253 2000 2404 2006 2010 6007 1996 6007 18886 3070 2015 3631 2061 2002 2699 2000 8081 2009 2044 2008 2002 2404 2006 2010 28130 1998 2002 2253 2000 1996 3902 16033 2361 1996 3902 2001 2525 2908 2002 2018 2696 2175 5252 2044 2009 1998 3492 2574 1996 3836 2056 2002 2001 2397 2005 2082 2045 2320 2020 2048 2336 2315 9606 1998 24003 2027 2020 13039 2006 1037 3137 2320 1998 2027 2387 2242 1999 1996 3712 2009 5565 2485 2000 2068 2027 2743 2369 1037 5747 1998 6601 1014 24003 2001 1037 6015 2100 11266 2000 2156 9606 2001 9191 2061 9606 2766 24003 2021 2002 4370 2145 2002 2052 2025 2175 2059 2009 2441 2035 1997 1996 5573 1037 2155 2001 2746 2041 1037 2611 7344 1037 3899 7344 1037 2388 7344 1037 3611 7344 1998 1037 2567 7344 2001 2145 1999 1996 10382 1996 3899 2001 27646 2068 1998 2253 2875 2068 2027 2387 2068 1998 2027 2020 6015 2027 2056 2054 2079 2017 2215 2007 2149 2498 2057 2074 2234 2000 3942 2115 4774 2057 1005 2128 2025 2667 2000 2202 2505 1037 3232 2420 2044 2008 2027 2020 5863 2290 5324 2061 2027 9828 2061 2027 4342 2123 1005 1056 4682 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] when the boy and girl got back from school the mother asked what do you wanna have for dinner and they shouted out mcdonald ##s so they left the house and went to mcdonald ##s and they went to the counter and the person who works there said twelve something and and their mother didn ' t have that much money because she realized that it was on the table and and the boy wanted a chicken burger with fries , and a vanilla milk ##sha ##ke and the mother wanted a salad and the sister wanted a chocolate ice + cream the boy had slept very late and he tried to eat his breakfast but the milk cart ##on broke and all the milk splashed out and then when he was trying to tie his shoe his shoe lace broke off and when he tried to get the bus the bus went without him because he was very late and then when he ran to school the principal said that he ' s too late one morning me and my friend went to the park and we saw a big , huge spaceship in the sky it landed right where our favorite tree was we saw a little girl with seven legs and we saw a mother with seven legs too and there are more aliens coming out of the spaceship it had fancy writing on the top of the spaceship and i wanted to see up close and my best friend tried to stop me and the dog had lots of hair on it and the woman alien raised up her hand like she was saying hi to me and we ran back to the house telling our parents and they didn ' t believe us then we brought our family to the park but the aliens wasn ' t there or the spaceship and our parents didn ' t believe us at the first moment [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] when the boy and girl got back from school the mother asked what do you wanna have for dinner and they shouted out mcdonald ##s so they left the house and went to mcdonald ##s and they went to the counter and the person who works there said twelve something and and their mother didn ' t have that much money because she realized that it was on the table and and the boy wanted a chicken burger with fries , and a vanilla milk ##sha ##ke and the mother wanted a salad and the sister wanted a chocolate ice + cream the boy had slept very late and he tried to eat his breakfast but the milk cart ##on broke and all the milk splashed out and then when he was trying to tie his shoe his shoe lace broke off and when he tried to get the bus the bus went without him because he was very late and then when he ran to school the principal said that he ' s too late one morning me and my friend went to the park and we saw a big , huge spaceship in the sky it landed right where our favorite tree was we saw a little girl with seven legs and we saw a mother with seven legs too and there are more aliens coming out of the spaceship it had fancy writing on the top of the spaceship and i wanted to see up close and my best friend tried to stop me and the dog had lots of hair on it and the woman alien raised up her hand like she was saying hi to me and we ran back to the house telling our parents and they didn ' t believe us then we brought our family to the park but the aliens wasn ' t there or the spaceship and our parents didn ' t believe us at the first moment [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2043 1996 2879 1998 2611 2288 2067 2013 2082 1996 2388 2356 2054 2079 2017 10587 2031 2005 4596 1998 2027 6626 2041 9383 2015 2061 2027 2187 1996 2160 1998 2253 2000 9383 2015 1998 2027 2253 2000 1996 4675 1998 1996 2711 2040 2573 2045 2056 4376 2242 1998 1998 2037 2388 2134 1005 1056 2031 2008 2172 2769 2138 2016 3651 2008 2009 2001 2006 1996 2795 1998 1998 1996 2879 2359 1037 7975 15890 2007 22201 1010 1998 1037 21161 6501 7377 3489 1998 1996 2388 2359 1037 16521 1998 1996 2905 2359 1037 7967 3256 1009 6949 1996 2879 2018 7771 2200 2397 1998 2002 2699 2000 4521 2010 6350 2021 1996 6501 11122 2239 3631 1998 2035 1996 6501 22055 2041 1998 2059 2043 2002 2001 2667 2000 5495 2010 10818 2010 10818 12922 3631 2125 1998 2043 2002 2699 2000 2131 1996 3902 1996 3902 2253 2302 2032 2138 2002 2001 2200 2397 1998 2059 2043 2002 2743 2000 2082 1996 4054 2056 2008 2002 1005 1055 2205 2397 2028 2851 2033 1998 2026 2767 2253 2000 1996 2380 1998 2057 2387 1037 2502 1010 4121 25516 1999 1996 3712 2009 5565 2157 2073 2256 5440 3392 2001 2057 2387 1037 2210 2611 2007 2698 3456 1998 2057 2387 1037 2388 2007 2698 3456 2205 1998 2045 2024 2062 12114 2746 2041 1997 1996 25516 2009 2018 11281 3015 2006 1996 2327 1997 1996 25516 1998 1045 2359 2000 2156 2039 2485 1998 2026 2190 2767 2699 2000 2644 2033 1998 1996 3899 2018 7167 1997 2606 2006 2009 1998 1996 2450 7344 2992 2039 2014 2192 2066 2016 2001 3038 7632 2000 2033 1998 2057 2743 2067 2000 1996 2160 4129 2256 3008 1998 2027 2134 1005 1056 2903 2149 2059 2057 2716 2256 2155 2000 1996 2380 2021 1996 12114 2347 1005 1056 2045 2030 1996 25516 1998 2256 3008 2134 1005 1056 2903 2149 2012 1996 2034 2617 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2043 1996 2879 1998 2611 2288 2067 2013 2082 1996 2388 2356 2054 2079 2017 10587 2031 2005 4596 1998 2027 6626 2041 9383 2015 2061 2027 2187 1996 2160 1998 2253 2000 9383 2015 1998 2027 2253 2000 1996 4675 1998 1996 2711 2040 2573 2045 2056 4376 2242 1998 1998 2037 2388 2134 1005 1056 2031 2008 2172 2769 2138 2016 3651 2008 2009 2001 2006 1996 2795 1998 1998 1996 2879 2359 1037 7975 15890 2007 22201 1010 1998 1037 21161 6501 7377 3489 1998 1996 2388 2359 1037 16521 1998 1996 2905 2359 1037 7967 3256 1009 6949 1996 2879 2018 7771 2200 2397 1998 2002 2699 2000 4521 2010 6350 2021 1996 6501 11122 2239 3631 1998 2035 1996 6501 22055 2041 1998 2059 2043 2002 2001 2667 2000 5495 2010 10818 2010 10818 12922 3631 2125 1998 2043 2002 2699 2000 2131 1996 3902 1996 3902 2253 2302 2032 2138 2002 2001 2200 2397 1998 2059 2043 2002 2743 2000 2082 1996 4054 2056 2008 2002 1005 1055 2205 2397 2028 2851 2033 1998 2026 2767 2253 2000 1996 2380 1998 2057 2387 1037 2502 1010 4121 25516 1999 1996 3712 2009 5565 2157 2073 2256 5440 3392 2001 2057 2387 1037 2210 2611 2007 2698 3456 1998 2057 2387 1037 2388 2007 2698 3456 2205 1998 2045 2024 2062 12114 2746 2041 1997 1996 25516 2009 2018 11281 3015 2006 1996 2327 1997 1996 25516 1998 1045 2359 2000 2156 2039 2485 1998 2026 2190 2767 2699 2000 2644 2033 1998 1996 3899 2018 7167 1997 2606 2006 2009 1998 1996 2450 7344 2992 2039 2014 2192 2066 2016 2001 3038 7632 2000 2033 1998 2057 2743 2067 2000 1996 2160 4129 2256 3008 1998 2027 2134 1005 1056 2903 2149 2059 2057 2716 2256 2155 2000 1996 2380 2021 1996 12114 2347 1005 1056 2045 2030 1996 25516 1998 2256 3008 2134 1005 1056 2903 2149 2012 1996 2034 2617 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] once there was a mom and a girl named kathleen and a boy named raymond and the mom said let ' s go out to eat tonight and they said yeah how about mcdonald ##s and then they packed up in the car and went to mcdonald ##s the girl didn ' t know what she would order but raymond wanted a chocolate milk ##sha ##ke and a cheese ##burg ##er and the mom ordered a big _ mac and then the girl thought of what she wanted she wanted a happy ##me ##al so the clerk said that will be twelve dollars and then the mom found out that she left her purse on the counter at home once there was a boy called donald he got up in the morning and he got a good night ' s sleep but his head hurt he was really tired still he was trying to pour the milk into his cereal but the milk spilled all over the place then he he fixed it and he went to go tie his shoes but his shoes ##tri ##ng broke he was trying to catch the bus after but he got to the bus stop too late and he missed the bus he got to school late and the teacher was sort of angry but she was okay with it he had a better day once there was a man and a girl the girl ' s name was lina and the man ' s name was jack they were going to the park to have a picnic and then they saw something very strange in the sky it landed at the park these weird looking things were coming out they had a lot of legs and polka + dots all over them they had a weird looking animal or is it an animal lina wanted to go see them but jack jack said no they might be aliens and then lina was going to go say hi she ran and went to go say hi but then they said they were nice and they had a picnic together and they all went home [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] once there was a mom and a girl named kathleen and a boy named raymond and the mom said let ' s go out to eat tonight and they said yeah how about mcdonald ##s and then they packed up in the car and went to mcdonald ##s the girl didn ' t know what she would order but raymond wanted a chocolate milk ##sha ##ke and a cheese ##burg ##er and the mom ordered a big _ mac and then the girl thought of what she wanted she wanted a happy ##me ##al so the clerk said that will be twelve dollars and then the mom found out that she left her purse on the counter at home once there was a boy called donald he got up in the morning and he got a good night ' s sleep but his head hurt he was really tired still he was trying to pour the milk into his cereal but the milk spilled all over the place then he he fixed it and he went to go tie his shoes but his shoes ##tri ##ng broke he was trying to catch the bus after but he got to the bus stop too late and he missed the bus he got to school late and the teacher was sort of angry but she was okay with it he had a better day once there was a man and a girl the girl ' s name was lina and the man ' s name was jack they were going to the park to have a picnic and then they saw something very strange in the sky it landed at the park these weird looking things were coming out they had a lot of legs and polka + dots all over them they had a weird looking animal or is it an animal lina wanted to go see them but jack jack said no they might be aliens and then lina was going to go say hi she ran and went to go say hi but then they said they were nice and they had a picnic together and they all went home [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2320 2045 2001 1037 3566 1998 1037 2611 2315 14559 1998 1037 2879 2315 7638 1998 1996 3566 2056 2292 1005 1055 2175 2041 2000 4521 3892 1998 2027 2056 3398 2129 2055 9383 2015 1998 2059 2027 8966 2039 1999 1996 2482 1998 2253 2000 9383 2015 1996 2611 2134 1005 1056 2113 2054 2016 2052 2344 2021 7638 2359 1037 7967 6501 7377 3489 1998 1037 8808 4645 2121 1998 1996 3566 3641 1037 2502 1035 6097 1998 2059 1996 2611 2245 1997 2054 2016 2359 2016 2359 1037 3407 4168 2389 2061 1996 7805 2056 2008 2097 2022 4376 6363 1998 2059 1996 3566 2179 2041 2008 2016 2187 2014 8722 2006 1996 4675 2012 2188 2320 2045 2001 1037 2879 2170 6221 2002 2288 2039 1999 1996 2851 1998 2002 2288 1037 2204 2305 1005 1055 3637 2021 2010 2132 3480 2002 2001 2428 5458 2145 2002 2001 2667 2000 10364 1996 6501 2046 2010 20943 2021 1996 6501 13439 2035 2058 1996 2173 2059 2002 2002 4964 2009 1998 2002 2253 2000 2175 5495 2010 6007 2021 2010 6007 18886 3070 3631 2002 2001 2667 2000 4608 1996 3902 2044 2021 2002 2288 2000 1996 3902 2644 2205 2397 1998 2002 4771 1996 3902 2002 2288 2000 2082 2397 1998 1996 3836 2001 4066 1997 4854 2021 2016 2001 3100 2007 2009 2002 2018 1037 2488 2154 2320 2045 2001 1037 2158 1998 1037 2611 1996 2611 1005 1055 2171 2001 27022 1998 1996 2158 1005 1055 2171 2001 2990 2027 2020 2183 2000 1996 2380 2000 2031 1037 12695 1998 2059 2027 2387 2242 2200 4326 1999 1996 3712 2009 5565 2012 1996 2380 2122 6881 2559 2477 2020 2746 2041 2027 2018 1037 2843 1997 3456 1998 29499 1009 14981 2035 2058 2068 2027 2018 1037 6881 2559 4111 2030 2003 2009 2019 4111 27022 2359 2000 2175 2156 2068 2021 2990 2990 2056 2053 2027 2453 2022 12114 1998 2059 27022 2001 2183 2000 2175 2360 7632 2016 2743 1998 2253 2000 2175 2360 7632 2021 2059 2027 2056 2027 2020 3835 1998 2027 2018 1037 12695 2362 1998 2027 2035 2253 2188 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2320 2045 2001 1037 3566 1998 1037 2611 2315 14559 1998 1037 2879 2315 7638 1998 1996 3566 2056 2292 1005 1055 2175 2041 2000 4521 3892 1998 2027 2056 3398 2129 2055 9383 2015 1998 2059 2027 8966 2039 1999 1996 2482 1998 2253 2000 9383 2015 1996 2611 2134 1005 1056 2113 2054 2016 2052 2344 2021 7638 2359 1037 7967 6501 7377 3489 1998 1037 8808 4645 2121 1998 1996 3566 3641 1037 2502 1035 6097 1998 2059 1996 2611 2245 1997 2054 2016 2359 2016 2359 1037 3407 4168 2389 2061 1996 7805 2056 2008 2097 2022 4376 6363 1998 2059 1996 3566 2179 2041 2008 2016 2187 2014 8722 2006 1996 4675 2012 2188 2320 2045 2001 1037 2879 2170 6221 2002 2288 2039 1999 1996 2851 1998 2002 2288 1037 2204 2305 1005 1055 3637 2021 2010 2132 3480 2002 2001 2428 5458 2145 2002 2001 2667 2000 10364 1996 6501 2046 2010 20943 2021 1996 6501 13439 2035 2058 1996 2173 2059 2002 2002 4964 2009 1998 2002 2253 2000 2175 5495 2010 6007 2021 2010 6007 18886 3070 3631 2002 2001 2667 2000 4608 1996 3902 2044 2021 2002 2288 2000 1996 3902 2644 2205 2397 1998 2002 4771 1996 3902 2002 2288 2000 2082 2397 1998 1996 3836 2001 4066 1997 4854 2021 2016 2001 3100 2007 2009 2002 2018 1037 2488 2154 2320 2045 2001 1037 2158 1998 1037 2611 1996 2611 1005 1055 2171 2001 27022 1998 1996 2158 1005 1055 2171 2001 2990 2027 2020 2183 2000 1996 2380 2000 2031 1037 12695 1998 2059 2027 2387 2242 2200 4326 1999 1996 3712 2009 5565 2012 1996 2380 2122 6881 2559 2477 2020 2746 2041 2027 2018 1037 2843 1997 3456 1998 29499 1009 14981 2035 2058 2068 2027 2018 1037 6881 2559 4111 2030 2003 2009 2019 4111 27022 2359 2000 2175 2156 2068 2021 2990 2990 2056 2053 2027 2453 2022 12114 1998 2059 27022 2001 2183 2000 2175 2360 7632 2016 2743 1998 2253 2000 2175 2360 7632 2021 2059 2027 2056 2027 2020 3835 1998 2027 2018 1037 12695 2362 1998 2027 2035 2253 2188 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdb9_hGYWfLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz4jMC_MWiB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpEdw6U4Wiuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2lPm2jaWkns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-fd6PvkWmL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCHUn9vXWnxf",
        "colab_type": "code",
        "outputId": "4cee447c-1adf-4c6d-a4b7-4e2cee54445e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://nlp_sli_bucket/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f71a623d5c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://nlp_sli_bucket/output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f71a623d5c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeXaZZluWpfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8ge0sDVWrgf",
        "colab_type": "code",
        "outputId": "9883e710-18f4-4e02-9459-7e1c55b36159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-ca03218f28a6>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-ca03218f28a6>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into gs://nlp_sli_bucket/output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into gs://nlp_sli_bucket/output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.7259795, step = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.7259795, step = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 12 vs previous value: 12. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 12 vs previous value: 12. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 16 vs previous value: 16. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 16 vs previous value: 16. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 26 vs previous value: 26. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 26 vs previous value: 26. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 36 vs previous value: 36. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 36 vs previous value: 36. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 39 vs previous value: 39. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 39 vs previous value: 39. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 78 into gs://nlp_sli_bucket/output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 78 into gs://nlp_sli_bucket/output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.13655458.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.13655458.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  0:31:21.144356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYQeSSdYWt4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXV16hSIWvd5",
        "colab_type": "code",
        "outputId": "cafd1b0c-a828-4e46-f98a-e1085277b9ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        }
      },
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-04-03T21:14:20Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-04-03T21:14:20Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://nlp_sli_bucket/output/model.ckpt-78\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://nlp_sli_bucket/output/model.ckpt-78\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-04-03-21:15:48\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-04-03-21:15:48\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 78: auc = 0.7614031, eval_accuracy = 0.84689, f1_score = 0.6363636, false_negatives = 18.0, false_positives = 14.0, global_step = 78, loss = 0.37883696, precision = 0.6666667, recall = 0.6086956, true_negatives = 149.0, true_positives = 28.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 78: auc = 0.7614031, eval_accuracy = 0.84689, f1_score = 0.6363636, false_negatives = 18.0, false_positives = 14.0, global_step = 78, loss = 0.37883696, precision = 0.6666667, recall = 0.6086956, true_negatives = 149.0, true_positives = 28.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 78: gs://nlp_sli_bucket/output/model.ckpt-78\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 78: gs://nlp_sli_bucket/output/model.ckpt-78\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.7614031,\n",
              " 'eval_accuracy': 0.84689,\n",
              " 'f1_score': 0.6363636,\n",
              " 'false_negatives': 18.0,\n",
              " 'false_positives': 14.0,\n",
              " 'global_step': 78,\n",
              " 'loss': 0.37883696,\n",
              " 'precision': 0.6666667,\n",
              " 'recall': 0.6086956,\n",
              " 'true_negatives': 149.0,\n",
              " 'true_positives': 28.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z29j-X4hWx2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPrediction(in_sentences):\n",
        "  labels = [\"TD\", \"SLI\"]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}